<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>SparseSync - Vladimir Iashin</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="css/style.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="icon" href="./favicon.ico" type="image/x-icon">
  </head>
  <style>
    .lrs_examples {
       padding-bottom: 1em;
    }
    .lrs_example_row {
       display: flex;
       flex-direction: row;
       padding-bottom: 1em;
    }
    .lrs_example {
       display: flex;
       flex-direction: row;
       padding: 0 1.5em 0 1.5em;
    }
    .class_lrs_column {
      display: flex;
      flex-direction: column;
      align-items: center;
      text-align: center;
      padding: 0 0.2em 0 0.2em;
    }
    .arrow {
      font-size: 150%;
      margin: auto;
      font-weight: 800;
    }
    .vggsound_example_row {
       display: flex;
       flex-direction: row;
       padding-bottom: 1em;
    }
    .class_video_column {
      flex: 1;
      display: flex;
      flex-direction: column;
      align-items: center;
      text-align: center;
      padding: 0 1em 0 1em;
    }
    .video_class {
      font-weight: 800;
    }
    .scalable_vid {
      flex: 1 1 auto;
      aspect-ratio: 16 / 9;
      width: 100%;
    }
    body {
      -webkit-text-size-adjust: none;
      -moz-text-size-adjust: none;
      -ms-text-size-adjust: none;
    }
    :root {
      font-size: 5px;
    }
    @media (min-width: 320px) and (max-width: 1081.6px){
      :root {
        font-size: -webkit-calc( 5px + (16 - 5) * ( (100vw - 320px) / (1081.6 - 320) ));
        font-size: -moz-calc( 5px + (16 - 5) * ( (100vw - 320px) / (1081.6 - 320) ));
        font-size: -o-calc( 5px + (16 - 5) * ( (100vw - 320px) / (1081.6 - 320) ));
        font-size: calc( 5px + (16 - 5) * ( (100vw - 320px) / (1081.6 - 320) ));
      }
    }
    @media (min-width: 1081.6px){
      :root {
        font-size: 16px;
      }
    }
    a.intext:link, a.social:link, a.bread_crumb:link {
      border-bottom-width: 0.05em;
    }
    table {
      border-spacing: 0 5px;
      margin-left: auto;
      margin-right: auto;
      border-top: 0.15em solid black;
      border-bottom: 0.15em solid black;
      margin-bottom: 0.15em;
      border-collapse: collapse;
      padding-bottom: 3em;
    }
    thead {
      border-bottom: 0.1em solid black;
      border-spacing: 5px 5px;
    }
    th {
      border-spacing: 5px 5px;
    }
    tr.mid_rule {
      border-bottom: 0.1em solid black;
    }
    th.left_border, td.left_border{
      border-left: 0.1em solid black;
    }
    th, td {
      padding: 0.4em 1em 0.4em 1em;
      text-align: right;
    }
    .rotate {
      -ms-writing-mode: tb-rl;
      -webkit-writing-mode: vertical-rl;
      writing-mode: vertical-rl;
      transform: rotate(180deg);
      white-space: nowrap;
    }
    img.gt {
      border: 0.3em solid black;
    }
    img.rec_vggsound_with_vggsound {
      border: 0.3em solid #99FFFF;
    }
    img.rec_vas_with_vggsound {
      border: 0.3em solid #CC99FF;
    }
    img.rec_vas_with_vas {
      border: 0.3em solid #FFCC99;
    }
    img.black_border {
      border: 0.22em solid black;
    }
    div.middle {
      margin: auto 0em auto 0em;
    }
    div.rec_results, div.sampling_results {
      text-align: center;
      font-size: 0.8em;
      line-height: 1.4em;
    }
    div.bold {
      font-weight: bold;
    }
    div.italic {
      font-style: italic;
    }
    .zero_font_size_and_line_hight {
      line-height: 0em;
    }
    details {
      border: 0.15em solid black;
      padding: 0.5em;
    }
    summary {
      cursor: pointer;
    }
    /* Popup */
    .popup_link {
      color: black;
      border-bottom: 0.1em dotted;
      color: #333;
    }
    .popup {
      position: relative;
      display: inline-block;
    }
    .popup_content {
      text-align: left;
      display: none;
      position: absolute;
      background-color: white;
      border: 0.075em solid lightgray;
      padding: 1em;
      border-radius: 1em;
      box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.2);
      z-index: 1;
      width: 20em;
      left: 50%;
      transform: translateX(-50%);
    }
    .popup:hover .popup_content {
      display: block;
    }
    /* hopefully helps with hovers on touch screens */
    .popup:active .popup_content {
      display: block;
    }
    /* Double Border Color */
    .double {
      float: left;
      position: relative;
      padding: 0.22em;
      background: #01BAEF;
    }
    .double:after {
      content: "";
      display: block;
      position: absolute;
      width: 50%;
      height: 100%;
      background: #20BF55;
      right: 0;
      bottom: 0;
    }
    .double img {
      position: relative;
      z-index: 1;
    }
    /* Top-X overlay */
    .topx_overlay {
      border: 0.075em solid black;
      background-color: rgba(255, 255, 255, 0.4);
      padding: 0.3em;
    }
    /* ToC */
    ul {
      padding-left: 2em;
    }
    li {
      display: list-item;
    }
    .toc_section {
      padding-top: 2em;
    }
    .toc_subsection {
      padding-top: 0.7em;
      font-size: 0.8em;
      padding-bottom: 0em;
    }
    #toc_container li, #toc_container ul, #toc_container ul li {
      list-style: outside none none !important;
    }
  </style>

  <body>
    <ul class="breadcrumb">
      <a class="bread_crumb" href="index.html">Vladimir Iashin</a> / Audio-visual Synchronisation with Trainable Selectors
    </ul>

    <h1> Sparse in Space and Time: <br> Audio-visual Synchronisation with Trainable Selectors </h1>

    <!-- Authors -->
    <div class="container_authors">
      <div class="author_affiliation">
        <div class="author_name">
          <a class="social" href="https://v-iashin.github.io/"> Vladimir Iashin </a>
        </div>
        <div class="affiliation"> Tampere University </div>
        <div class="affiliation"> <br> </div>
      </div>
      <div class="author_affiliation">
        <div class="author_name">
          <a class="social" href="https://weidixie.github.io/"> Weidi Xie </a>
        </div>
        <div class="affiliation"> Shanghai Jiao Tong University </div>
        <div class="affiliation"> University of Oxford </div>
      </div>
      <div class="author_affiliation">
        <div class="author_name">
          <a class="social" href="https://esa.rahtu.fi/"> Esa Rahtu </a>
        </div>
        <div class="affiliation"> Tampere University </div>
        <div class="affiliation"> <br> </div>
      </div>
      <div class="author_affiliation">
        <div class="author_name">
          <a class="social" href="https://www.robots.ox.ac.uk/~az/"> Andrew Zisserman </a>
        </div>
        <div class="affiliation"> University of Oxford </div>
        <div class="affiliation"> <br> </div>
      </div>
    </div>

    <!-- Conference -->
    <div class="conference">
      <!-- <a class="social" href="https://www.bmvc2021-virtualconference.com/conference/papers/paper_1213.html"> British Machine Vision Conference (BMVC), 2022 – <b>Spotlight Presentation</b> </a> -->
      <div style="font-size: larger;">British Machine Vision Conference (BMVC), 2022 – <b>Spotlight Presentation</b></div>
    </div>

    <!-- Links -->
    <div class="code_and_links">
      <div style="padding: 1em 0 1em 0;" class="div_link">
        <a class="social" href="https://github.com/v-iashin/SparseSync"> Code & Models </a>
      </div>
      <div style="padding: 1em 0 1em 0;" class="div_link">
        <a class="social" href="https://arxiv.org/abs/2210.07055"> Paper </a>
      </div>
      <div style="padding: 1em 0 1em 0;" class="div_link">
        <a class="social" href="./assets/sparsesync/vggsound_sparse.csv">Download Dataset (.csv)</a>
      </div>
      <div style="padding: 1em 0 1em 0;" class="div_link">
        <a class="social" href="https://colab.research.google.com/drive/1rawAPksDHUioSXcAbQTn_kMbDl3nYg8q?usp=sharing"> Demo on Google Colab </a>
      </div>
      <!-- <div style="padding: 1em 0 1em 0;" class="div_link"> <a class="social" href="https://www.youtube.com/watch?v=C4zYVIqGDVQ"> Presentation (YouTube) </a> </div> -->
      <!-- <div style="padding: 1em 0 1em 0;" class="div_link"> <a class="social" href="https://arxiv.org/abs/2005.08271"> Paper </a> </div> -->
    </div>


    <!-- <div id="overview" style="padding-top: 3em;" class="our_framework">
      <div class="section_name"> Overview </div>
      <div class="section_content">
        <p class="p_on_project_pages">
          Audio-visual synchronisation requires a model to relate changes in the visual and audio streams.
          The objective of this paper is the synchronisation of general videos 'in the wild'.
          For such videos, the events that may be harnessed for synchronisation cues may be
          spatially small and may occur only infrequently during a many seconds-long video clip,
          i.e. the synchronisation signal is 'sparse in space and time'.
          This contrasts with the case of synchronising videos of talking heads,
          where audio-visual correspondence is dense in both time and space.
        </p>
      </div>
    </div> -->

    <div class="our_framework" style="padding-top: 3em;" >
      <div class="section_name"> Dense vs. Sparse Synchronisation Signals </div>
      <div class="section_content">
        <div class="img background_white_squared" style="border: none; padding: 0em;">
          <img src="./images/sparsesync/sparse_selector_teaser.png"
               alt="Comparison of dense and sparse synchronisation signals" >
        </div>
        <p class="p_on_project_pages">
          Audio-visual synchronisation requires a model to relate changes in the visual and audio streams.
          Prior work focused primarily on the synchronisation of talking head videos (left).
          In contrast, open-domain videos often have a small visual indication, i.e. sparse in space (right).
          Moreover, cues may be intermittent and scattered, i.e. sparse across time, e.g. a lion only
          roars once during a video clip.
        </p>
      </div>
    </div>

    <div class="our_framework">
      <div class="section_name">Synchronising Videos with Sparse Synchronisation Signal</div>
      <div class="section_content">
        <div class="img background_white_squared" style="border: none; padding: 0em;">
          <img src="./images/sparsesync/sparse_selector_arch.png"
               alt="The overview of the proposed architecture (SparseSync)" >
        </div>
        <p class="p_on_project_pages">
          It is well-known that transformers have flattered many areas of deep learning including video
          understanding.
          Despite reaching the state-of-the-art in many tasks, it scales quadratically with input length.
          Moreover, the fine-grained audio-visual synchronisation of videos with sparse cues
          requires higher frame rate, resolution, and duration.
          To this end, we propose SparseSelector, a transformer-based architecture that enables the
          processing of long videos with linear complexity with respect to the duration of a video clip.
          It achieves this by 'compressing' the audio and visual
          input tokens into two small sets of learnable selectors.
          These selectors form an input to a transformer which predicts the temporal offset between the
          audio and visual streams.
        </p>
      </div>
    </div>

    <div class="our_framework">
      <div class="section_name"> <i>VGGSound-Sparse:</i> Video Dataset with Sparse Audio-visual Cues </div>
      <div class="section_content">

        <div class="vggsound_examples" style="padding-bottom: 2em;">

          <div class="vggsound_example_row">
            <div class="class_video_column">
              <div class="video_class">striking bowling</div>
              <iframe class="scalable_vid" src="https://www.youtube-nocookie.com/embed/e9ECf2ZGBdk?start=211&end=221" title="YouTube player" allowfullscreen></iframe>
            </div>
            <div class="class_video_column">
              <div class="video_class">lion roaring</div>
              <iframe class="scalable_vid" src="https://www.youtube-nocookie.com/embed/GCDWVj9BjU8?start=12&end=22" title="YouTube player" allowfullscreen></iframe>
            </div>
            <div class="class_video_column">
              <div class="video_class">dog barking</div>
              <iframe class="scalable_vid" src="https://www.youtube-nocookie.com/embed/JXBNGfDy2DY?start=354&end=364" title="YouTube player" allowfullscreen></iframe>
            </div>
          </div>

          <div class="vggsound_example_row">
            <div class="class_video_column">
              <div class="video_class">skateboarding</div>
              <iframe class="scalable_vid" src="https://www.youtube-nocookie.com/embed/lNG8l7BtwQo?start=0&end=10" title="YouTube player" allowfullscreen></iframe>
            </div>
            <div class="class_video_column">
              <div class="video_class">chopping wood</div>
              <iframe class="scalable_vid" src="https://www.youtube-nocookie.com/embed/JMpqsef4w8g?start=18&end=28" title="YouTube player" allowfullscreen></iframe>
            </div>
            <div class="class_video_column">
              <div class="video_class">playing tennis</div>
              <iframe class="scalable_vid" src="https://www.youtube-nocookie.com/embed/ZYc410CE4Rg?start=0&end=10" title="YouTube player" allowfullscreen></iframe>
            </div>
          </div>

          <!-- If other ones will be unavailable with time -->
          <!-- <div class="vggsound_example_row">
            <div class="class_video_column">
              <div class="video_class">hammering nails</div>
              <iframe class="scalable_vid" src="https://www.youtube-nocookie.com/embed/Lo6-F9U-qUg?start=2&end=12" title="YouTube player" allowfullscreen></iframe>
            </div>
            <div class="class_video_column">
              <div class="video_class">playing badminton</div>
              <iframe class="scalable_vid" src="https://www.youtube-nocookie.com/embed/Map8EOl5fbk?start=61&end=71" title="YouTube player" allowfullscreen></iframe>
            </div>
            <div class="class_video_column">
              <div class="video_class">people sneezing</div>
              <iframe class="scalable_vid" src="https://www.youtube-nocookie.com/embed/PjK77Fekmnc?start=120&end=130" title="YouTube player" allowfullscreen></iframe>
            </div>
          </div> -->

        </div>

        <p class="p_on_project_pages">
          Opposed to a <i>dense in time and space</i> dataset (e.g. cropped talking faces as in
          <a href="https://www.robots.ox.ac.uk/~vgg/data/lip_reading/lrs3.html" class="intext">LRS3</a>),
          we are interested in solving synchronisation on <i>sparse in time and space</i> videos.
          Due to its challenging nature, a public benchmark to measure progress has not yet been established.
          To bridge this gap, we curate a subset of
          <a href="https://www.robots.ox.ac.uk/~vgg/data/vggsound/" class="intext">VGGSound</a>
          of videos with audio-visual correspondence that is <i>sparse in time and space</i>.
          We call it <b>VGGSound-Sparse</b>.
          It consists of 6.5k videos and spans 12 'sparse' classes such as
          <i>dog barking</i>, <i>chopping wood</i>, <i>skateboarding</i>, etc.
        </p>
        <p class="p_on_project_pages">
          Download annotations:
          <a href="./assets/sparsesync/vggsound_sparse.csv" class="intext">vggsound_sparse.csv</a>
        </p>
      </div>
    </div>

    <div class="our_framework">
      <div class="section_name"> <i>LRS3-H.264 ('No Face Crop'):</i> Dense in Time but Sparse in Space </div>
      <div class="section_content">
        <div class="lrs_examples">

          <div class="lrs_example_row">

            <div class="lrs_example">
              <div class="class_lrs_column" style="flex: 18">
                <div class="video_class">LRS3</div>
                <img class="black_border" src="./images/sparsesync/lrs_examples/01GWGmg5jn8_00001_orig.jpg">
              </div>
              <div class="class_lrs_column" style="flex: 1;">
                <div class="arrow"> → </div>
              </div>
              <div class="class_lrs_column" style="flex: 32">
                <div class="video_class">LRS3 ('No Face Crop')</div>
                <img class="black_border" src="./images/sparsesync/lrs_examples/01GWGmg5jn8_00001_nfc.jpg">
              </div>
            </div>

            <div class="lrs_example">
              <div class="class_lrs_column" style="flex: 18">
                <div class="video_class">LRS3</div>
                <img class="black_border" src="./images/sparsesync/lrs_examples/G17iMOw0ar8_00001_orig.jpg">
              </div>
              <div class="class_lrs_column" style="flex: 1">
                <div class="arrow"> → </div>
              </div>
              <div class="class_lrs_column" style="flex: 32">
                <div class="video_class">LRS3 ('No Face Crop')</div>
                <img class="black_border" src="./images/sparsesync/lrs_examples/G17iMOw0ar8_00001_nfc.jpg">
              </div>
            </div>

          </div>

          <div class="lrs_example_row">

            <div class="lrs_example">
              <div class="class_lrs_column" style="flex: 18">
                <img class="black_border" src="./images/sparsesync/lrs_examples/i0QKBKWnkxg_00001_orig.jpg">
              </div>
              <div class="class_lrs_column" style="flex: 1;">
                <div class="arrow"> → </div>
              </div>
              <div class="class_lrs_column" style="flex: 32">
                <img class="black_border" src="./images/sparsesync/lrs_examples/i0QKBKWnkxg_00001_nfc.jpg">
              </div>
            </div>

            <div class="lrs_example">
              <div class="class_lrs_column" style="flex: 18">
                <img class="black_border" src="./images/sparsesync/lrs_examples/l141Mauo74A_00001_orig.jpg">
              </div>
              <div class="class_lrs_column" style="flex: 1">
                <div class="arrow"> → </div>
              </div>
              <div class="class_lrs_column" style="flex: 32">
                <img class="black_border" src="./images/sparsesync/lrs_examples/l141Mauo74A_00001_nfc.jpg">
              </div>
            </div>

          </div>

        </div>

        <p class="p_on_project_pages">
          In addition to the VGGSound-Sparse dataset, we encourage benchmarking future models on
          videos from LRS3 dataset without the tight face crop or, as we refer to it,
          <i>dense in time but sparse in space</i>.
          The shift from the cropped setting to uncropped one is motivated by the following two arguments:<br>
          1) The LRS3 dataset can be considered to be 'solved' as models reach 95%
          performance and above with as few as 11 RGB frames; <br>
          2) The videos that are officially distributed are encoded in
          <a href="https://en.wikipedia.org/wiki/MPEG-4_Part_2" class="intext">MPEG-4 Part 2</a>, a codec with a strict
          I-frame temporal locations which might encourage a model to learn a shortcut rather than
          semantic audio-visual correspondence (see later sections and the paper for details). <br>
        </p>
        <p class="p_on_project_pages">
          In this project, we retrieve the original videos of LRS3 from YouTube and call this variation
          <b>LRS3-H.264 ('No Face Crop')</b>.
          Furthermore, these videos are encoded with the
          <a href="https://en.wikipedia.org/wiki/Advanced_Video_Coding" class="intext">H.264</a>
          video codec which has a more complicated frame-prediction algorithm compared to the MPEG-4 Pt. 2
          which makes it hard for a model to learn a 'shortcut'.
          <i>Note, simply transcoding from MPEG-4 Pt. 2 to H.264 does not solve the issue</i>.
        </p>
      </div>
    </div>

    <div class="our_framework">
      <div class="section_name"> Synchronisation Results </div>
        <div class="section_content">
          <table>
            <thead>
              <tr>
                <th></th>
                <th style="font-weight: normal; font-style: italic;"> LRS3 ('No Face Crop') </th>
                <th style="font-weight: normal; font-style: italic;"> VGGSound-Sparse</th>
              </tr>
              <tr>
                <th></th>
                <th>
                  <div class="popup">
                    <div class="popup_content" style="font-weight: normal;">
                      21 offset classes from –2.0 to +2.0 sec with 0.2-sec step size.
                      The metric tolerates ±1 temporal class (±0.2 sec) mistakes.</div>
                    <a class="popup_link"> Accuracy </a>
                  </div>
                </th>
                <th>
                  <div class="popup">
                    <div class="popup_content" style="font-weight: normal;">
                      21 offset classes from –2.0 to +2.0 sec with 0.2-sec step size.
                      The metric tolerates ±1 temporal class (±0.2 sec) mistakes.</div>
                    <a class="popup_link"> Accuracy </a>
                  </div>
                </th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>
                  <a href="https://arxiv.org/abs/2112.04432" class="intext">AVST<sub>dec</sub> </a>
                </td>
                <td>83.1</td>
                <td>29.3</td>
              </tr>
              <tr style="border-bottom: 0.1em solid black">
                <td>Ours</td>
                <td>96.9</td>
                <td>44.3</td>
              </tr>
            </tbody>
          </table>
          <p style="padding-top: 2em;" class="p_on_project_pages">
            We open-source the code and the pre-trained models
            <a href="https://github.com/v-iashin/SparseSync" class="intext">GitHub</a>.
            For a quick start, you may check our
            <a href="https://colab.research.google.com/drive/1rawAPksDHUioSXcAbQTn_kMbDl3nYg8q?usp=sharing" class="intext">Google Colab Demo</a>.
          </p>
        </div>
      </div>

  </body>

  <!-- Prefetching the hidden images for snappier toggles -->
  <!-- <img src="./images/bmt/encoder.png" style="display: none;">
  <img src="./images/bmt/decoder.png" style="display: none;">
  <img src="./images/mdvc.gif" style="display: none;"> -->
  </html>
